{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imperial-income",
   "metadata": {},
   "source": [
    "# Analysing Trail Run Results from cycosports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-toyota",
   "metadata": {},
   "source": [
    "The data is publicly available from https://cycosports.com/2021-jungle-cross-trail-run-april-3rd-4th/ in PDF format. The table data needs to be extracted from the PDF. We will be analysing the results from 4th April.\n",
    "\n",
    "https://pdftables.com/ was able to reasonably generate Excel/CSV versions of the datset. The CSV version is used. However, this website only offers 25 pages of free conversions. \n",
    "\n",
    "An alternative free site which gives a reasonable output is https://www.pdftoexcelconverter.net/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-system",
   "metadata": {},
   "source": [
    "# 1. Preparing the data\n",
    "\n",
    "We will aim to transform this data into a tidy data format as defined by Hadley Wickham (https://en.wikipedia.org/wiki/Tidy_data).\n",
    "\n",
    "First, we import the necessary libraries and load the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('results.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-praise",
   "metadata": {},
   "source": [
    "Then, we standardise the format of the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {\"Pl\":\"category_rank\", \"overall\":\"event_rank\", \"1stLap\":\"lap_1\", \"2ndLap\":\"lap_2\"})\n",
    "df = df.rename(str.lower, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-consistency",
   "metadata": {},
   "source": [
    "## Removing the rows with no usable data\n",
    "\n",
    "* The data contains some rows with the string \"Jungle Cross 2021 Trail Run Series Race 2\". \n",
    "* There are also repeated header rows (with the values \"Pl\", \"overall\", \"Name\", etc.) within the data. This is due to the PDF repeating them for each page. \n",
    "* Also, the rows containing \"DNS\" and \"DNF\" (in the \"Pl\" and \"overall\" data columns) do not have timing information associated with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-preservation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-coordinator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-final",
   "metadata": {},
   "source": [
    "We will remove those rows from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"category_rank\"].str.contains(\"Jungle Cross 2021\", na=False, regex=False)]\n",
    "df = df[~df[\"name\"].str.contains(\"Jungle Cross 2021\", na=False, regex=False)]\n",
    "df = df[~df[\"time\"].str.contains(\"Time\", na=False, regex=False)]\n",
    "df = df[~df[\"category_rank\"].str.contains(\"DNS|DNF\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-surgery",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "The inversion operator (`~`) is used to return rows not containing the terms. Alternatively, the following can be used:\n",
    "\n",
    "`df = df[df[\"column\"].str.contains(\"substring\", na=False)==False]`\n",
    "\n",
    "`regex=False` should not be used if there are regex expressions such as `\"DNS|DNF\"`.\n",
    "\n",
    "`na=False` must be used, as the string methods cannot work where values are not a string (e.g. NaN). \n",
    "Running the code without `na=False` will result in (for the given column) dropping rows with \n",
    "not only the specifed substring, but also those with NaN values.\n",
    "\n",
    "If we want to verify which rows are being dropped, the code can be run on the original DataFrame but without the inversion, \n",
    "to get back a DataFrame with only those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-appreciation",
   "metadata": {},
   "source": [
    "## Dealing with the event and gender data in the \"category_rank\" column\n",
    "\n",
    "The DataFrame has additional information in the \"category_rank\" column. The items are: \n",
    "* race event (e.g. \"10km - Masters (40+)\") \n",
    "* gender (Male or Female) \n",
    "* age category (e.g. Open, Masters, Under 14) in that order. \n",
    "\n",
    "They are in their own header rows with no other information. \n",
    "\n",
    "This information has to be split out into their own columns to keep the \"category_rank\" column clean.\n",
    "\n",
    "### Creating columns for distance, event and age\n",
    "\n",
    "We can search for rows containing \"km\", but with first resetting the index to synchronise it with the actual row numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-sending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df[df[\"category_rank\"].str.contains(\"km\", na=False, regex=False, case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-program",
   "metadata": {},
   "source": [
    "By running the above code, we can see that there are only 3 race events. Hence, we can use their locations to manually fill a new column via slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"race\"] = \"\"\n",
    "df.loc[:91, \"race\"] = \"10km - Open - 13+\"\n",
    "df.loc[91:142,\"race\"] = \"10km - Masters - 40+\"\n",
    "df.loc[142:,\"race\"] = \"3km - Adventure Race - 7+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-london",
   "metadata": {},
   "source": [
    "We then remove the now-redundant header rows. We can also split the information in the new column into more granular columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0, 91, 142])\n",
    "\n",
    "df[[\"distance\",\"event\", \"age\"]] = df[\"race\"].str.split(\"-\",expand=True)\n",
    "df = df.drop(columns=[\"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-subject",
   "metadata": {},
   "source": [
    "### Creating a column for gender\n",
    "\n",
    "We can prepare the \"gender\" column by first making a copy of the \"category_rank\" column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = df[\"category_rank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-battery",
   "metadata": {},
   "source": [
    "However, there are 14 header rows for gender as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[\"gender\"].str.fullmatch(\"Male|Female\", na=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-directory",
   "metadata": {},
   "source": [
    "Hence, we will not use the manual method as shown above, but we will replace all the non-gender values in the column with NaN. This then allows us to forward-fill the values (down the column) from the remaining headers to complete the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"][~df[\"gender\"].str.fullmatch(\"Male|Female\", na=False)] = np.nan\n",
    "df[\"gender\"] = df.gender.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-innocent",
   "metadata": {},
   "source": [
    "### Creating a column for category\n",
    "\n",
    "Again, we can create the column by copying the current \"category_rank\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category_rank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-marsh",
   "metadata": {},
   "source": [
    "Replacing the rank numbers in the column with NaN values allows us to forward-fill the category information to complete the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace(to_replace='\\d+\\.\\d*', value=np.nan, regex=True)\n",
    "df[\"category\"] = df[\"category\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-edgar",
   "metadata": {},
   "source": [
    "Following that, we can strip excess gender information from this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"category\",\"sex\"]] = df[\"category\"].str.split(\"-\",expand=True)\n",
    "df = df.drop(columns=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-elder",
   "metadata": {},
   "source": [
    "### Removing rows with no time \n",
    "\n",
    "At this point, the DataFrame still has the remaining header rows under \"category_rank\". These rows have no values under the \"time\" column. \n",
    "\n",
    "To clean the data up, we will simply remove all rows with NaN values under \"time\".\n",
    "\n",
    "After this, the \"category_rank\" column should be clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"time\"])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-objective",
   "metadata": {},
   "source": [
    "## Dealing with the bib number\n",
    "\n",
    "The \"name\" column has additional information regarding the bib number. It is possible to extract that information into a new column and then remove it from the \"name\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bib_number\"] = df[\"name\"].str.extract(\"\\((\\d+)\\)\",expand=True)\n",
    "df[\"name\"] = df[\"name\"].str.split(\"(\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-consent",
   "metadata": {},
   "source": [
    "There are some entries without a bib number, so we will fill those with the string \"None\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bib_number\"] = df['bib_number'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-delhi",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-encoding",
   "metadata": {},
   "source": [
    "## Removing NaN values from the \"club\" column\n",
    "\n",
    "For consistency, we will do the same for NaN values in the \"club\" column as we did for the \"bib_number\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['club'] = df['club'].fillna(\"None\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-preservation",
   "metadata": {},
   "source": [
    "Now, we have values in all cells of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-retail",
   "metadata": {},
   "source": [
    "## Properly formatting the duration-based columns\n",
    "\n",
    "The \"lap_1\", \"lap_2\" and \"time\" columns contain duration information. Analysis requires conversion to the Pandas timedelta object. However, using the columns as they are will throw errors with `pd.to_timedelta`. \n",
    "\n",
    "Within the same column, some entries are in `%M:%S.%f`(MM:SS:ff) and some are in `%-H:%M:%S.%f` (H:MM:SS:ff) format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[60:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-commission",
   "metadata": {},
   "source": [
    "As long as we change the `%M:%S.%f` entries to `%-H:%M:%S.%f` so that the whole column is consistent, `pd.to_timedelta` will accept it. \n",
    "\n",
    "However, we will change both the `%M:%S.%f` and the `%-H:%M:%S.%f` entries in the column to `%H:%M:%S.%f` (HH:MM:SS:ff) as it is more conventional. \n",
    "\n",
    "There are three ways we can write functions to update the formats. The functions will add the respective zero digits and semicolons to the strings where applicable. \n",
    "\n",
    "### Method 1: Counting the number of \":\" in the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-factory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_hours_zero(column):\n",
    "    m = column.str.count(':') == 2\n",
    "    column = column.mask(m, \"0\" + column, axis=0)\n",
    "    return column\n",
    "\n",
    "def add_hours(column):\n",
    "    m = column.str.count(':') == 1\n",
    "    column = column.mask(m, \"00:\" + column, axis=0)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-ghost",
   "metadata": {},
   "source": [
    "### Method 2: Measuring the length of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours_zero(column):\n",
    "    m = column.str.len() == 10\n",
    "    column = column.mask(m, \"0\" + column, axis=0)\n",
    "    return column\n",
    "\n",
    "def add_hours(column):\n",
    "    m = column.str.len() == 8\n",
    "    column = column.mask(m, \"00:\" + column, axis=0)\n",
    "    return column  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-julian",
   "metadata": {},
   "source": [
    "### Method 3: Using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours_zero(column):\n",
    "    m = column.str.contains(\"^\\d+:\\d+:\\d+\\.\\d+$\", na=False)\n",
    "    column = column.mask(m, \"0\" + column, axis=0)\n",
    "    return column\n",
    "\n",
    "def add_hours(column):\n",
    "    m = column.str.contains(\"^\\d+:\\d+\\.\\d+$\", na=False)\n",
    "    column = column.mask(m, \"00:\" + column, axis=0)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-japanese",
   "metadata": {},
   "source": [
    "### Applying the functions\n",
    "\n",
    "Note that `add_hours_zero` must be applied before `add_hours` to work properly on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"lap_1\", \"lap_2\", \"time\"]] = df[[\"lap_1\", \"lap_2\", \"time\"]].apply(add_hours_zero)\n",
    "df[[\"lap_1\", \"lap_2\", \"time\"]] = df[[\"lap_1\", \"lap_2\", \"time\"]].apply(add_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[60:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-march",
   "metadata": {},
   "source": [
    "## Formatting the \"start\" column to datetime format \n",
    "\n",
    "The \"start\" column contains the race start time of the runner on that day. After formatting it to datetime format, year-month-day placeholders appear in the entries. We can specify the actual date of the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start\"] = pd.to_datetime(df[\"start\"], format=\"%H:%M:%S.%f\")\n",
    "df[\"start\"] = df[\"start\"].map(lambda x: x.replace(year=2021, month=4, day=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-circumstances",
   "metadata": {},
   "source": [
    "## Casting of types for the rank columns \n",
    "\n",
    "The \"category_rank\" and \"event_rank\" columns are of dtype: object and appear formatted as a float in the dataframe. We can change them to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category_rank\"] = pd.to_numeric(df[\"category_rank\"]).astype(int)\n",
    "df[\"event_rank\"] = pd.to_numeric(df[\"event_rank\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-beijing",
   "metadata": {},
   "source": [
    "## Exporting the cleaned data to .csv \n",
    "\n",
    "Now, we can export the data, and re-import it to validate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results_clean.csv\", index=False )\n",
    "df = pd.read_csv('results_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-federation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-portland",
   "metadata": {},
   "source": [
    "--End of Part 1--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
